# include:
  # - template: Container-Scanning.gitlab-ci.yml

variables:
  LABREPO_HOST: "labrepo.sil.lab"
  TFPLENUM_EXPORT_LOC: "/mnt/drive_creation/"
  TFPLENUM_EXPORT_VERSION: RC
  TFPLENUM_CONFLUENCE_PAGE: "6.8 CVAH 3.3"
  TFPLENUM_COMMIT_HASH: $CI_COMMIT_REF_NAME
  PIPELINE: "developer"
  BUILD_TYPE: "clone_from_nightly"
  IS_CLEANUP: "false"
  VMWARE_FOLDER: "Testing"
  NETWORK_ID: "10.40.12.0"
  VMWARE_DATASTORE: "NVMe Storage 2"
  SONAR_TOKEN: "88288e09065a3d865d20a10c05563b3225566490"
  SONAR_HOST_URL: "http://sonarqube.sil.lab:9000/"
  GIT_DEPTH: 0
  ACAS_IPADDRESS: "172.16.82.15"
  ACAS_USERNAME: "acas"
  ACAS_PASSWORD: "we.are.tfplenum"
  ACAS_SCAN_TO_RUN: "Scan test Kit1"
  RUN_ACAS: "false"
  DNS_SERVERS: "10.10.101.11 10.10.101.12 10.11.101.13"
  REPO_BRANCH: $CI_COMMIT_REF_NAME
  REPO_URL: "https://gitlab.sil.lab/tfplenum/tfplenum.git"
  VCENTER_IPADDRESS: "10.10.103.10"
  VCENTER_DATACENTER: "DEV_Datacenter"
  VCENTER_PORTGROUP: "12-Dev2-Navarro"
  VCENTER_DATASTORE: "NVMe Storage"
  TEMPLATE_TO_CLONE: "dip-ctrl.lan"
  VM_GATEWAY: "10.40.12.1"

  #The VM prefix is the prefix for all the VMs that will be created.
  #EX <VM_PREFIX>-ctrl.lan | <VM_PREFIX>-sensor1.lan | <VM_PREFIX>-server1.lan
  VM_PREFIX: "test1"
  NUM_SERVERS: 2
  NUM_SENSORS: 1
  SERVER_CPU: 32
  SERVER_MEM: 30720
  SENSOR_CPU: 24
  SENSOR_MEM: 30720


stages:
  - code-analysis
  - pre-build
  - build
  - docs
  - kickstart
  - kit
  - security_scans
  - catalog
  - unit-test
  - integration-test
  - test-powerfailure
  - rerun-integration-test
  - cleanup
  - export
  - hashfiles
  - publish

sonarqube-check:
  tags:
    - tfplenum-buildv2
  stage: code-analysis
  script: |
    echo "IP of runner is $(hostname -I)"
    echo "Current working directory is $(pwd)"
    sonar-scanner -Dsonar.qualitygate.wait=true -Dsonar.projectKey=tfplenum -Dsonar.sources=web/
  allow_failure: true
  only:
    variables:
      - $PIPELINE == "virtual_build_and_test"
      - $PIPELINE == "developer"
      - $CI_PIPELINE_SOURCE == "push"

# container_scanning:
#   image:
#     name: gitlab.sil.lab:5050/tfplenum/tfplenum/klair:2
#     entrypoint: []
#   variables:
#     GIT_STRATEGY: clone
#     CI_APPLICATION_REPOSITORY: gitlab.sil.lab:5050/tfplenum/tfplenum/zeek
#     CI_APPLICATION_TAG: 3.0.0
#   artifacts:
#     paths:
#       - gl-container-scanning-report.json
#     reports:
#       container_scanning: gl-container-scanning-report.json
#   tags:
#     - tfplenum-docker
#   only:
#     variables:
#       - $PIPELINE == "code_quality"

Create artifacts folder:
  stage: pre-build
  tags:
    - tfplenum-buildv2
  script: |
    echo "IP of runner is $(hostname -I)"
    echo "Current working directory is $(pwd)"
    rm -rf $TFPLENUM_EXPORT_LOC/$TFPLENUM_EXPORT_VERSION
    mkdir -p $TFPLENUM_EXPORT_LOC/$TFPLENUM_EXPORT_VERSION
  only:
    variables:
      - $PIPELINE == "export"

Setup Nightly Controller:
  stage: build
  tags:
    - tfplenum-buildv2
  script: |
    echo "IP of runner is $(hostname -I)"
    echo "Current working directory is $(pwd)"
    python3 testing/pipeline/pipeline.py setup-controller \
    --vcenter-ipaddress "$VCENTER_IPADDRESS" \
    --vcenter-username "$VCENTER_USERNAME" \
    --vcenter-password "$VCENTER_PASSWORD" \
    --vcenter-datacenter "$VCENTER_DATACENTER" \
    --repo-username "$REPO_USERNAME" \
    --repo-password "$REPO_PASSWORD" \
    --repo-url "$REPO_URL" \
    --portgroup "$VCENTER_PORTGROUP" \
    --network-id "$NETWORK_ID" \
    --dns-server $DNS_SERVERS \
    --vm-folder "$VMWARE_FOLDER" \
    --vm-template "$TEMPLATE_TO_CLONE" \
    --gateway "$VM_GATEWAY" \
    --vm-prefix "$VM_PREFIX" \
    --branch-name "$REPO_BRANCH" \
    --run-type build_from_scratch \
    --vm-datastore "$VCENTER_DATASTORE"
  only:
    variables:
      - $PIPELINE == "daily_build"

Build Offline Documentation:
  stage: build
  tags:
    - tfplenum-buildv2
  script: |
    echo "IP of runner is $(hostname -I)"
    echo "Current working directory is $(pwd)"
    python3 testing/pipeline/pipeline.py run-export export-html-docs \
    --username "$CONFLUENCE_USERNAME" \
    --password "$CONFLUENCE_PASSWORD" \
    --export-path "$TFPLENUM_EXPORT_LOC" \
    --export-version "$TFPLENUM_EXPORT_VERSION" \
    --page-title "$TFPLENUM_CONFLUENCE_PAGE"

    python3 testing/pipeline/pipeline.py run-export export-single-page-pdf \
    --username "$CONFLUENCE_USERNAME" \
    --password "$CONFLUENCE_PASSWORD" \
    --export-path "$TFPLENUM_EXPORT_LOC" \
    --export-version "$TFPLENUM_EXPORT_VERSION" \
    --page-titles "6.8.1.2 DIP System Setup" "6.8.1.1 MIP System Setup" "6.8.2.1 DIP System Operation" "6.8.2.2 MIP System Operation" "6.8.9.4 Windows Agent Plugin Guide" "6.8.9.5 Helm Integration" "6.8.9.2 Setup Controller"
  only:
    variables:
      - $PIPELINE == "export"

Ship Phyical Stack Build:
  stage: build
  tags:
    - tfplenum-buildv2
  script: |
    echo "IP of runner is $(hostname -I)"
    echo "Current working directory is $(pwd)"
    zip -r physical-stack-build-$TFPLENUM_EXPORT_VERSION.zip infrastucture/
    cp physical-stack-build-$TFPLENUM_EXPORT_VERSION.zip $TFPLENUM_EXPORT_LOC/$TFPLENUM_EXPORT_VERSION
  only:
    variables:
      - $PIPELINE == "export"

Setup Controller:
  stage: build
  tags:
    - tfplenum-buildv2
  script: |
    echo "IP of runner is $(hostname -I)"
    echo "Current working directory is $(pwd)"
    echo "dip-cache-${CI_PIPELINE_ID}"

    if [ $CI_PIPELINE_SOURCE == "push" ]; then
        export NUM_SENSORS=2
        export BUILD_TYPE="clone_from_nightly"
        export VMWARE_FOLDER="Testing"
        export VM_PREFIX="test${CI_PIPELINE_ID}"
        export TEMPLATE_TO_CLONE="dip-ctrl.lan"
    fi

    echo "VM_PREFIX is $VM_PREFIX"
    python3 testing/pipeline/pipeline.py setup-controller \
    --vcenter-ipaddress "$VCENTER_IPADDRESS" \
    --vcenter-username "$VCENTER_USERNAME" \
    --vcenter-password "$VCENTER_PASSWORD" \
    --vcenter-datacenter "$VCENTER_DATACENTER" \
    --repo-username "$REPO_USERNAME" \
    --repo-password "$REPO_PASSWORD" \
    --repo-url "$REPO_URL" \
    --portgroup "$VCENTER_PORTGROUP" \
    --network-id "$NETWORK_ID" \
    --dns-server $DNS_SERVERS \
    --vm-folder "$VMWARE_FOLDER" \
    --vm-template "$TEMPLATE_TO_CLONE" \
    --gateway "$VM_GATEWAY" \
    --vm-prefix "$VM_PREFIX" \
    --branch-name "$REPO_BRANCH" \
    --run-type "$BUILD_TYPE" \
    --vm-datastore "$VCENTER_DATASTORE"
  cache:
    key: dip-cache-${CI_PIPELINE_ID}
    paths:
      - controllersetupsettings.yml
  only:
    variables:
      - $PIPELINE == "virtual_build_and_test"
      - $PIPELINE == "export"
      - $PIPELINE == "developer"
      - $CI_PIPELINE_SOURCE == "push"

Run Python Unit Tests:
  tags:
    - tfplenum-buildv2
  stage: unit-test
  script: |
    echo "IP of runner is $(hostname -I)"
    echo "Current working directory is $(pwd)"
    python3 testing/pipeline/pipeline.py run-unit-tests
  allow_failure: true
  cache:
    key: dip-cache-${CI_PIPELINE_ID}
    paths:
      - controllersetupsettings.yml
      - kickstartsettings.yml
    policy: pull
  only:
    variables:
      - $PIPELINE == "virtual_build_and_test"
      - $PIPELINE == "developer"
      - $CI_PIPELINE_SOURCE == "push"

Add Docs to Controller:
  stage: docs
  tags:
    - tfplenum-buildv2
  script: |
    echo "IP of runner is $(hostname -I)"
    echo "Current working directory is $(pwd)"
    python3 testing/pipeline/pipeline.py run-export add-docs-to-controller \
    --username "$CONFLUENCE_USERNAME" \
    --password "$CONFLUENCE_PASSWORD" \
    --export-path "$TFPLENUM_EXPORT_LOC" \
    --export-version "$TFPLENUM_EXPORT_VERSION" \
    --page-title "$TFPLENUM_CONFLUENCE_PAGE"
  cache:
    key: dip-cache-${CI_PIPELINE_ID}
    paths:
      - controllersetupsettings.yml
    policy: pull
  only:
    variables:
      - $PIPELINE == "export"
  artifacts:
    paths:
      - "htmlcov.zip"

Kickstart:
  stage: kickstart
  tags:
    - tfplenum-buildv2
  script: |
    echo "IP of runner is $(hostname -I)"
    echo "Current working directory is $(pwd)"

    if [ $CI_PIPELINE_SOURCE == "push" ]; then
        export NUM_SENSORS=2
        export VMWARE_FOLDER="Testing"
        export VM_PREFIX="test${CI_PIPELINE_ID}"
    fi

    echo "VM_PREFIX is $VM_PREFIX"
    python3 testing/pipeline/pipeline.py run-kickstart \
    --vcenter-ipaddress "$VCENTER_IPADDRESS" \
    --vcenter-username "$VCENTER_USERNAME" \
    --vcenter-password "$VCENTER_PASSWORD" \
    --vcenter-datacenter "$VCENTER_DATACENTER" \
    --portgroup "$VCENTER_PORTGROUP" \
    --network-id "$NETWORK_ID" \
    --dns-server $DNS_SERVERS \
    --vm-folder "$VMWARE_FOLDER" \
    --vm-prefix "$VM_PREFIX" \
    --gateway "$VM_GATEWAY" \
    --num-servers $NUM_SERVERS \
    --num-sensors $NUM_SENSORS \
    --server-cpu $SERVER_CPU \
    --server-mem $SERVER_MEM \
    --sensor-cpu $SENSOR_CPU \
    --sensor-mem $SENSOR_MEM \
    --vm-datastore "$VCENTER_DATASTORE"
  cache:
    key: dip-cache-${CI_PIPELINE_ID}
    paths:
      - controllersetupsettings.yml
      - kickstartsettings.yml
      - nodestoscan.txt
  only:
    variables:
      - $PIPELINE == "virtual_build_and_test"
      - $PIPELINE == "developer"
      - $CI_PIPELINE_SOURCE == "push"

Deploy Kit:
  stage: kit
  tags:
    - tfplenum-buildv2
  script: |
    echo "IP of runner is $(hostname -I)"
    echo "Current working directory is $(pwd)"
    python3 testing/pipeline/pipeline.py run-kit
  cache:
    key: dip-cache-${CI_PIPELINE_ID}
    paths:
      - controllersetupsettings.yml
      - kickstartsettings.yml
      - kitsettings.yml
      - nodestoscan.txt
  only:
    variables:
      - $PIPELINE == "virtual_build_and_test"
      - $PIPELINE == "developer"
      - $CI_PIPELINE_SOURCE == "push"

Perform Security Scans:
  stage: security_scans
  tags:
    - tfplenum-buildv2
  script: |
    echo "IP of runner is $(hostname -I)"
    echo "Current working directory is $(pwd)"
    python3 testing/testy-tester/run_acas.py \
    --ipaddress "$ACAS_IPADDRESS" \
    --username "$ACAS_USERNAME" \
    --password "$ACAS_PASSWORD" \
    --scan_name "$ACAS_SCAN_TO_RUN" \
    --nodes-to-scan $(cat nodestoscan.txt)
  cache:
    key: dip-cache-${CI_PIPELINE_ID}
    paths:
      - nodestoscan.txt
    policy: pull
  only:
    variables:
      - $RUN_ACAS == "true"
  artifacts:
    paths:
      - "TFPlenum_ACAS_Report.pdf"

CVAH Catalog:
  stage: catalog
  tags:
    - tfplenum-buildv2
  script: |
    echo "IP of runner is $(hostname -I)"
    echo "Current working directory is $(pwd)"
    python3 testing/pipeline/pipeline.py run-catalog suricata
    python3 testing/pipeline/pipeline.py run-catalog moloch-capture
    python3 testing/pipeline/pipeline.py run-catalog moloch-viewer
    python3 testing/pipeline/pipeline.py run-catalog zeek
    python3 testing/pipeline/pipeline.py run-catalog logstash
  cache:
    key: dip-cache-${CI_PIPELINE_ID}
    paths:
      - controllersetupsettings.yml
      - kickstartsettings.yml
      - kitsettings.yml
    policy: pull
  only:
    variables:
      - $PIPELINE == "virtual_build_and_test"
      - $CI_PIPELINE_SOURCE == "push"

System Function Testing:
  stage: integration-test
  tags:
    - tfplenum-buildv2
  script: |
    echo "IP of runner is $(hostname -I)"
    echo "Current working directory is $(pwd)"
    python3 testing/pipeline/pipeline.py run-integration-tests
  only:
    variables:
      - $PIPELINE == "virtual_build_and_test"
      - $CI_PIPELINE_SOURCE == "push"
  cache:
    key: dip-cache-${CI_PIPELINE_ID}
    paths:
      - controllersetupsettings.yml
      - kickstartsettings.yml
      - kitsettings.yml
    policy: pull
  artifacts:
    paths:
      - "./*.xml"
    reports:
      junit: "./*.xml"

Simulate Power Failure:
  stage: test-powerfailure
  tags:
    - tfplenum-buildv2
  script: |
    echo "IP of runner is $(hostname -I)"
    echo "Current working directory is $(pwd)"
    python3 testing/pipeline/pipeline.py simulate-power-failure
  cache:
    key: dip-cache-${CI_PIPELINE_ID}
    paths:
      - controllersetupsettings.yml
      - kickstartsettings.yml
      - kitsettings.yml
    policy: pull
  only:
    variables:
      - $PIPELINE == "virtual_build_and_test"

System Function Testing2:
  stage: rerun-integration-test
  tags:
    - tfplenum-buildv2
  script: |
    echo "IP of runner is $(hostname -I)"
    echo "Current working directory is $(pwd)"
    python3 testing/pipeline/pipeline.py run-integration-tests
  cache:
    key: dip-cache-${CI_PIPELINE_ID}
    paths:
      - controllersetupsettings.yml
      - kickstartsettings.yml
      - kitsettings.yml
    policy: pull
  only:
    variables:
      - $PIPELINE == "virtual_build_and_test"
  artifacts:
    paths:
      - "./*.xml"
    reports:
      junit: "./*.xml"

Cleanup Job:
  stage: cleanup
  tags:
    - tfplenum-buildv2
  script: |
    echo "IP of runner is $(hostname -I)"
    echo "Current working directory is $(pwd)"
    python3 testing/pipeline/pipeline.py run-cleanup
  when: always
  cache:
    key: dip-cache-${CI_PIPELINE_ID}
    paths:
      - controllersetupsettings.yml
      - kickstartsettings.yml
      - kitsettings.yml
    policy: pull
  only:
    variables:
      - $IS_CLEANUP == "true"
      - $CI_PIPELINE_SOURCE == "push"

Export Controller:
  stage: export
  tags:
    - tfplenum-buildv2
  script: |
    echo "IP of runner is $(hostname -I)"
    echo "Current working directory is $(pwd)"
    python3 testing/pipeline/pipeline.py run-export export-ctrl \
    --export-path "$TFPLENUM_EXPORT_LOC" \
    --export-version "$TFPLENUM_EXPORT_VERSION"
  cache:
    key: dip-cache-${CI_PIPELINE_ID}
    paths:
      - controllersetupsettings.yml
    policy: pull
  only:
    variables:
      - $PIPELINE == "export"

Generate Versions File:
  stage: hashfiles
  tags:
    - tfplenum-buildv2
  script: |
    echo "IP of runner is $(hostname -I)"
    echo "Current working directory is $(pwd)"
    python3 testing/pipeline/pipeline.py run-export generate-versions-file \
    --export-path "$TFPLENUM_EXPORT_LOC" \
    --export-version "$TFPLENUM_EXPORT_VERSION"
  only:
    variables:
      - $PIPELINE == "export"

# Publish to Labrepo:
#   stage: publish
#   tags:
#     - tfplenum-buildv2
#   script: |
#     echo "IP of runner is $(hostname -I)"
#     echo "Current working directory is $(pwd)"
#     python pipeline.py publish \
#     --username "$LABREPO_USER" \
#     --password "$LABREPO_PASS" \
#     --ipaddress "$LABREPO_HOST" \
#     --export-path "$TFPLENUM_EXPORT_LOC" \
#     --export-version "$TFPLENUM_EXPORT_VERSION"
#   only:
#     variables:
#       - $PIPELINE == "export"
