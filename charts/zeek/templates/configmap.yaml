{{- $d := dict "manager" (dict "type" "manager" "port" 47760) -}}
{{- $_ := set $d "proxy" (dict "type" "proxy" "port" 47761) -}}
{{- range $i, $e := until (.Values.zeek_loggers | int) -}}
{{- $_ := set $d (printf "logger-%d" $i) (dict "type" "logger" "logger_number" $i "port" (add 47762 $i)) -}}
{{- range $interface_idx, $interface := $.Values.interfaces -}}
{{- range $i, $e := until ($.Values.zeek_workers | int) -}}
{{- $_ := set $d (printf "%s-%d" $interface $i) (dict "type" "worker" "interface" (printf "af_packet::%s" $interface) "port" (add 47762 ($.Values.zeek_loggers | int) $i (mul ($.Values.zeek_workers | int) $interface_idx))) -}}
{{- end -}}
{{- end -}}
{{- end -}}
---

apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}
  labels:
    component: zeek
data:
  cluster-layout.zeek: |
    redef Cluster::manager_is_logger = F;
    redef Cluster::nodes = {
{{- range $node, $config := $d }}
        ["{{ $node }}"] = [
            $node_type=Cluster::{{ $config.type | upper }},
            $ip=127.0.0.1, $p={{ $config.port }}/tcp,
{{- if $config.interface }}
            $interface="{{ $config.interface }}",
{{- end }}
            $manager="manager"
        ],
{{- end }}
    };

    @if ( Cluster::local_node_type() == Cluster::WORKER )
{{- range $i, $interface := .Values.interfaces }}
    @if ( Cluster::nodes[Cluster::node]$interface == "af_packet::{{ $interface }}" )
    redef AF_Packet::fanout_id = {{ add 22 $i }};
    @endif
{{- end }}
    @endif

  local.zeek: |
    # Load some defaults
    @load misc/loaded-scripts
    @load tuning/defaults
    @load misc/capture-loss
    @load misc/stats
    @load misc/scan
    @load frameworks/software/vulnerable
    @load frameworks/software/version-changes
    @load-sigs frameworks/signatures/detect-windows-shells
    @load protocols/ftp/software
    @load protocols/smtp/software
    @load protocols/ssh/software
    @load protocols/http/software
    @load protocols/dns/detect-external-names
    @load protocols/ftp/detect
    @load protocols/conn/known-hosts
    @load protocols/conn/known-services
    @load protocols/ssl/known-certs
    @load protocols/ssl/validate-certs
    @load protocols/ssl/validate-ocsp
    @load protocols/ssl/notary
    @load protocols/ssl/log-hostcerts-only
    @load protocols/ssh/geo-data
    @load protocols/ssh/detect-bruteforcing
    @load protocols/ssh/interesting-hostnames
    @load protocols/http/detect-sqli
    @load frameworks/files/hash-all-files
    @load frameworks/files/detect-MHR
    @load policy/frameworks/notice/extend-email/hostnames
    @load base/protocols/smb
    @load policy/frameworks/intel/seen
    @load frameworks/intel/do_notice
    @load frameworks/files/hash-all-files

    # Load tfplenum scripts
    @load ./tfplenum

    # TFPlenum-specific things
    @load custom # Rules provided by operator
    @load Corelight/CommunityID # Community ID plugin

    redef Log::default_rotation_interval = {{ .Values.ids_log_rotate_interval }} secs;
    redef Control::controllee_listen = F;

    redef Site::local_nets = {
{{- if has "any" .Values.home_net }}
        0.0.0.0/0,
        [::]/0,
{{- else }}
    {{- range .Values.home_net }}
        {{ . }},
{{- end }}
{{- end }}
    };

    @load tuning/json-logs
    redef LogAscii::json_timestamps = JSON::TS_ISO8601;
    redef LogAscii::use_json = T;

    # Add some basic info to all the connection records.
    global sensor_name = ""; # Hostname for this box.
    global interface_full = ""; # Interface we are listening on
    global interface_name = "";

    event zeek_init()
        {
        if ( Cluster::local_node_type() == Cluster::WORKER )
            {
            sensor_name = gethostname();
            interface_full = Cluster::nodes[Cluster::node]$interface;
            interface_name = subst_string(interface_full, "af_packet::", "");
            }
        }

    type Extension: record {
        stream:   string &log;
        ## The name of the system that wrote this log. This
        ## is defined in the  const so that
        ## a system running lots of processes can give the
        ## same value for any process that writes a log.
        system:   string &log;
        interface:   string &log;
        ## The name of the process that wrote the log. In
        ## clusters, this will typically be the name of the
        ## worker that wrote the log.
        proc:     string &log;
    };
    function add_log_extension(path: string): Extension
    {
        return Extension($stream = path,
                        $system = sensor_name,
                        $interface = interface_name,
                        $proc   = peer_description);
    }
    redef Log::default_ext_func   = add_log_extension;
    redef Log::default_ext_prefix = "@";
    redef Log::default_scope_sep  = "_";

    redef Kafka::topic_name = "zeek-raw";
    redef Kafka::json_timestamps = JSON::TS_ISO8601;
    redef Kafka::tag_json = F;

    # Enable bro logging to kafka for all logs
    event zeek_init() &priority=-5
    {
        for (stream_id in Log::active_streams)
        {
            if (|Kafka::logs_to_send| == 0 || stream_id in Kafka::logs_to_send)
            {
                local filter: Log::Filter = [
                    $name = fmt("kafka-%s", stream_id),
                    $writer = Log::WRITER_KAFKAWRITER,
                    $config = table(["stream_id"] = fmt("%s", stream_id))
                ];

                Log::add_filter(stream_id, filter);
            }
        }
    }


---

apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-scripts
  labels:
    component: zeek
data:
  __load__.zeek: |
    # Custom Scripts
    @load ./ja3.zeek
    @load ./intel_ja3.zeek
    @load ./ja3s.zeek
    @load ./hassh.zeek
    @load ./new-certs.zeek
    @load ./ssl-add-cert-hash.zeek
    @load ./ssl-add-cert-date.zeek

{{ range $path, $_ :=  .Files.Glob  "files/*" }}
  {{ base $path }}: |
{{ $.Files.Get $path | indent 4 }}
{{ end }}

---

apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-beats-config
  labels:
    component: zeek
data:
  metricbeat.yml: |-
    metricbeat.config.modules:
      # Mounted `metricbeat-daemonset-modules` configmap:
      path: ${path.config}/modules.d/*.yml
      # Reload module configs as they change:
      reload.enabled: false
    metricbeat.modules:
    - module: kafka
      metricsets:
      - partition
      - consumergroup
      period: 10s
      hosts: ["localhost:9092"]
    - module: system
      enabled: false

    output.elasticsearch:
      hosts: ['https://${ELASTICSEARCH_HOST:elasticsearch}:${ELASTICSEARCH_PORT:9200}']
      username: ${ELASTICSEARCH_USERNAME}
      password: ${ELASTICSEARCH_PASSWORD}
      ssl.certificate_authorities: ["/etc/ssl/certs/container/ca.crt"]

    monitoring:
      enabled: true
      elasticsearch:
        username: ${ELASTICSEARCH_USERNAME}
        password: ${ELASTICSEARCH_PASSWORD}
