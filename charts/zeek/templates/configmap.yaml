{{- $d := dict "manager" (dict "type" "manager" "port" 47760) -}}
{{- $_ := set $d "proxy" (dict "type" "proxy" "port" 47761) -}}
{{- range $i, $e := until (.Values.zeek_loggers | int) -}}
{{- $_ := set $d (printf "logger-%d" $i) (dict "type" "logger" "logger_number" $i "port" (add 47762 $i)) -}}
{{- range $interface_idx, $interface := $.Values.interfaces -}}
{{- range $i, $e := until ($.Values.zeek_workers | int) -}}
{{- $_ := set $d (printf "%s-%d" $interface $i) (dict "type" "worker" "interface" (printf "af_packet::%s" $interface) "port" (add 47762 ($.Values.zeek_loggers | int) $i (mul ($.Values.zeek_workers | int) $interface_idx))) -}}
{{- end -}}
{{- end -}}
{{- end -}}
---

apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}
  labels:
    component: zeek
data:
  cluster-layout.bro: |
    redef Cluster::manager_is_logger = F;
    redef Cluster::nodes = {
{{- range $node, $config := $d }}
        ["{{ $node }}"] = [
            $node_type=Cluster::{{ $config.type | upper }},
            $ip=127.0.0.1, $p={{ $config.port }}/tcp,
{{- if $config.interface }}
            $interface="{{ $config.interface }}",
{{- end }}
            $manager="manager"
        ],
{{- end }}
    };

    @if ( Cluster::local_node_type() == Cluster::WORKER )
{{- range $i, $interface := .Values.interfaces }}
    @if ( Cluster::nodes[Cluster::node]$interface == "af_packet::{{ $interface }}" )
    redef AF_Packet::fanout_id = {{ add 22 $i }};
    @endif
{{- end }}
    @endif

  local.bro: |
    # Load some defaults
    @load misc/loaded-scripts
    @load tuning/defaults
    @load misc/capture-loss
    @load misc/stats
    @load misc/scan
    @load frameworks/software/vulnerable
    @load frameworks/software/version-changes
    @load-sigs frameworks/signatures/detect-windows-shells
    @load protocols/ftp/software
    @load protocols/smtp/software
    @load protocols/ssh/software
    @load protocols/http/software
    @load protocols/dns/detect-external-names
    @load protocols/ftp/detect
    @load protocols/conn/known-hosts
    @load protocols/conn/known-services
    @load protocols/ssl/known-certs
    @load protocols/ssl/validate-certs
    @load protocols/ssl/log-hostcerts-only
    @load protocols/ssh/geo-data
    @load protocols/ssh/detect-bruteforcing
    @load protocols/ssh/interesting-hostnames
    @load protocols/http/detect-sqli
    @load frameworks/files/hash-all-files
    @load frameworks/files/detect-MHR
    @load policy/frameworks/notice/extend-email/hostnames
    @load base/protocols/smb

    # TFPlenum-specific things
    @load custom # Rules provided by operator
    @load Corelight/CommunityID # Community ID plugin

    redef Log::default_rotation_interval = {{ .Values.ids_log_rotate_interval }} secs;
    redef Control::controllee_listen = F;

    redef Site::local_nets = {
{{- if has "any" .Values.home_net }}
        0.0.0.0/0,
        [::]/0,
{{- else }}
    {{- range .Values.home_net }}
        {{ . }},
{{- end }}
{{- end }}
    };

    @load tuning/json-logs
    redef LogAscii::json_timestamps = JSON::TS_ISO8601;
    redef LogAscii::use_json = T;

    # Add some basic info to all the connection records.
    global sensorname = ""; # Hostname for this box.
    global interface = ""; # Interface we are listening on

    redef record Conn::Info += {
        sensorname: string &log &optional;
        interface: string &log &optional;
    };

    event bro_init()
        {
        if ( Cluster::local_node_type() == Cluster::WORKER )
            {
            sensorname = gethostname();
            interface = Cluster::nodes[Cluster::node]$interface;
            }
        }

    event connection_state_remove(c: connection)
        {
        c$conn$sensorname = sensorname;
        c$conn$interface = interface;
        }

    ## Setup Kafka output
    @load Apache/Kafka/logs-to-kafka
    redef Kafka::tag_json = T;
    redef Kafka::logs_to_send = set(Conn::LOG, HTTP::LOG, DNS::LOG, DCE_RPC::LOG, DHCP::LOG, DNP3::LOG, DPD::LOG, Files::LOG, FTP::LOG, Intel::LOG, IRC::LOG, KRB::LOG, Modbus::LOG, mysql::LOG, Notice::LOG, NTLM::LOG, PE::LOG, RADIUS::LOG, RDP::LOG, RFB::LOG, Signatures::LOG, SIP::LOG, SMB::FILES_LOG, SMB::MAPPING_LOG, SMTP::LOG, SNMP::LOG, SOCKS::LOG, Software::LOG, SSH::LOG, SSL::LOG, Syslog::LOG, Tunnel::LOG, Weird::LOG, X509::LOG);
    redef Kafka::topic_name = "bro-raw";
    redef Kafka::kafka_conf = table(["metadata.broker.list"] = "localhost:9092");

---

apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-beats-config
  labels:
    component: zeek
data:
  metricbeat.yml: |-
    metricbeat.config.modules:
      # Mounted `metricbeat-daemonset-modules` configmap:
      path: ${path.config}/modules.d/*.yml
      # Reload module configs as they change:
      reload.enabled: false

    processors:
      - add_cloud_metadata:

    cloud.id: ${ELASTIC_CLOUD_ID}
    cloud.auth: ${ELASTIC_CLOUD_AUTH}

    setup.dashboards.enabled: true
    setup.kibana.host: "{{ .Values.kibana_fqdn }}:{{ .Values.kibana_port }}"

    output.elasticsearch:
      hosts: ['${ELASTICSEARCH_HOST:elasticsearch-master}:${ELASTICSEARCH_PORT:9200}']
      username: ${ELASTICSEARCH_USERNAME}
      password: ${ELASTICSEARCH_PASSWORD}

---

apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-beats-modules
  labels:
    component: zeek
data:
  kafka.yml: |-
    - module: kafka
      metricsets:
      - partition
      - consumergroup
      period: 10s
      hosts: ["localhost:9092"]
