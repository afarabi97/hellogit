Setup Controller:
  stage: build
  tags:
    - tfplenum-buildv2
  script: |
    echo "IP of runner is $(hostname -I | cut -d " " -f1)"
    echo "Current working directory is $(pwd)"
    echo "VM_PREFIX is $VM_PREFIX"
    echo "TEMPLATE TO CLONE IS $TEMPLATE_TO_CLONE"
    cmd="python3 testing/pipeline/pipeline.py
    setup-controller
    --vcenter-ipaddress   \"$VCENTER_IPADDRESS\"
    --vcenter-username    \"$VCENTER_USERNAME\"
    --vcenter-password    \"$VCENTER_PASSWORD\"
    --vcenter-datacenter  \"$VCENTER_DATACENTER\"
    --repo-username       \"$REPO_USERNAME\"
    --repo-password       \"$REPO_PASSWORD\"
    --repo-url            \"$REPO_URL\"
    --portgroup           \"$VCENTER_PORTGROUP\"
    --network-id          \"$NETWORK_ID\"
    --network-block-index $NETWORK_BLOCK_INDEX
    --dns-servers         $DNS_SERVERS
    --vm-folder           \"$VMWARE_FOLDER\"
    --vm-password         \"$DEFAULT_TEMPLATE_PASSWORD\"
    --export-password     \"$OVA_EXPORT_PASSWORD\"
    --vm-template         \"$TEMPLATE_TO_CLONE\"
    --gateway             \"$VM_GATEWAY\"
    --vm-prefix           \"$VM_PREFIX\"
    --domain              \"$KIT_DOMAIN\"
    --branch-name         \"$CI_COMMIT_REF_NAME\"
    --vm-datastore        \"$VCENTER_DATASTORE\"
    --ctrl-cpu            \"$CTRL_CPU\"
    --ctrl-memory         \"$CTRL_MEMORY\"
    --pipeline            \"$PIPELINE\"
    --commit-hash         \"$CI_COMMIT_SHORT_SHA\"
    --project-id          \"$CI_PROJECT_ID\"
    --access-token        \"$ACCESS_TOKEN\"
    --rpm-build           \"$RPM_BUILD\""
    echo "$cmd"
    eval $cmd
  artifacts:
    untracked: true
  extends: .controller

Create a standalone MinIO server:
  stage: build
  tags:
    - tfplenum-buildv2
  script: |
    args=(
      setup-minio
      --vcenter-ipaddress "$VCENTER_IPADDRESS"
      --vcenter-username "$VCENTER_USERNAME"
      --vcenter-password "$VCENTER_PASSWORD"
      --vcenter-datacenter "$VCENTER_DATACENTER"
      --portgroup "$VCENTER_PORTGROUP"
      --network-id "$NETWORK_ID"
      --network-block-index "$MINIO_NETWORK_BLOCK_INDEX"
      --dns-servers $DNS_SERVERS
      --vm-folder "$VMWARE_FOLDER"
      --vm-password "$DEFAULT_TEMPLATE_PASSWORD"
      --export-password "$OVA_EXPORT_PASSWORD"
      --vm-template "$MINIO_TEMPLATE_TO_CLONE"
      --gateway "$VM_GATEWAY"
      --vm-name "$VM_PREFIX-minio.$KIT_DOMAIN"
      --hostname "minio"
      --domain "$KIT_DOMAIN"
      --vm-datastore "$VCENTER_DATASTORE"
      --disk-size "$MINIO_DISK_SIZE"
      --storage-disk-size "$MINIO_STORAGE_SIZE"
      --cpu $MINIO_CPU
      --memory $MINIO_MEMORY
      --commit-hash "$CI_COMMIT_SHORT_SHA"
      --pipeline "$PIPELINE"
    )
    echo "${args[@]}"
    python3 testing/pipeline/pipeline.py "${args[@]}"
  only:
    variables:
      - $PIPELINE == "export-minio"
      - $PIPELINE == "export-all"
      - $PIPELINE == "export-gip"
      - $MINIO_VM == "yes" && $PIPELINE == "developer-all"
  artifacts:
    untracked: true

Kit Settings:
  stage: kit-settings
  tags:
    - tfplenum-buildv2
  script: |
    echo "IP of runner is $(hostname -I | cut -d " " -f1)"
    echo "Current working directory is $(pwd)"
    echo "VM_PREFIX is $VM_PREFIX"
    python3 testing/pipeline/pipeline.py \
    run-kit-settings \
    --vcenter-ipaddress "$VCENTER_IPADDRESS" \
    --vcenter-username "$VCENTER_USERNAME" \
    --vcenter-password "$VCENTER_PASSWORD" \
    --vcenter-datacenter "$VCENTER_DATACENTER" \
    --vcenter-datastore "$VCENTER_DATASTORE" \
    --vcenter-folder "$VMWARE_FOLDER" \
    --vcenter-portgroup "$VCENTER_PORTGROUP" \
    --vcenter-cluster "$VCENTER_CLUSTER" \
    --upstream-dns "$UPSTREAM_DNS" \
    --upstream-ntp "$UPSTREAM_NTP" \
    --gateway "$VM_GATEWAY" \
    --network-id "$NETWORK_ID" \
    --network-block-index $NETWORK_BLOCK_INDEX \
    --domain "$KIT_DOMAIN" \
    --kit-password "$DEFAULT_VM_PASSWORD"
  artifacts:
    untracked: true
  extends: .all-and-mip

Control Plane:
  stage: control-plane
  tags:
    - tfplenum-buildv2
  script: |
    echo "IP of runner is $(hostname -I | cut -d " " -f1)"
    echo "Current working directory is $(pwd)"
    echo "VM_PREFIX is $VM_PREFIX"
    python3 testing/pipeline/pipeline.py setup-control-plane
  extends: .all-and-mip

Server Setup:
  stage: server-setup
  tags:
    - tfplenum-buildv2
  script: |
    echo "IP of runner is $(hostname -I | cut -d " " -f1)"
    echo "Current working directory is $(pwd)"
    echo "VM_PREFIX is $VM_PREFIX"
    python3 testing/pipeline/pipeline.py \
    add-node \
    --node-type Server \
    --deployment-type Baremetal \
    --vm-prefix "$VM_PREFIX" \
    --cpu $SERVER_CPU \
    --memory $SERVER_MEM \
    --start-index 1 \
    --num-nodes $NUM_SERVERS \
    --os-raid "$VM_RAID" \
    --dns-servers $DNS_SERVERS
  artifacts:
    untracked: true
  only:
    variables:
      - $PIPELINE == "developer-all"

Kit Deploy:
  stage: deploy-kit
  tags:
    - tfplenum-buildv2
  script: |
    echo "IP of runner is $(hostname -I | cut -d " " -f1)"
    echo "Current working directory is $(pwd)"
    echo "Deploying Kit"
    python3 testing/pipeline/pipeline.py deploy-kit
  only:
    variables:
      - $PIPELINE == "developer-all"

Sensor Setup:
  stage: node-setup
  tags:
    - tfplenum-buildv2
  script: |
    echo "IP of runner is $(hostname -I | cut -d " " -f1)"
    echo "Current working directory is $(pwd)"
    echo "VM_PREFIX is $VM_PREFIX"
    START_INDEX=$(($NUM_SERVERS+1))
    echo "$START_INDEX"
    python3 testing/pipeline/pipeline.py \
    add-node \
    --node-type Sensor \
    --deployment-type Baremetal \
    --vm-prefix "$VM_PREFIX" \
    --cpu $SENSOR_CPU \
    --memory $SENSOR_MEM \
    --start-index $START_INDEX \
    --num-nodes $NUM_SENSORS \
    --os-raid "$VM_RAID" \
    --dns-servers $DNS_SERVERS
  retry: 2
  artifacts:
    untracked: true
  only:
    variables:
      - $PIPELINE == "developer-all"

Service Setup:
  stage: node-setup
  tags:
    - tfplenum-buildv2
  script: |
    echo "IP of runner is $(hostname -I | cut -d " " -f1)"
    echo "Current working directory is $(pwd)"
    echo "VM_PREFIX is $VM_PREFIX"
    START_INDEX=$(($NUM_SERVERS+$NUM_SENSORS+1))
    echo "$START_INDEX"
    python3 testing/pipeline/pipeline.py \
    add-node \
    --node-type Service \
    --deployment-type Virtual \
    --vm-prefix "$VM_PREFIX" \
    --cpu $SERVICE_CPU \
    --memory $SERVICE_MEM \
    --start-index $START_INDEX \
    --num-nodes $NUM_SERVICE_NODES \
    --os-raid "$VM_RAID" \
    --dns-servers $DNS_SERVERS
  retry: 2
  artifacts:
    untracked: true
  only:
    variables:
      - $PIPELINE == "developer-all"
      - $PIPELINE == "hw-developer-all"

MIP Setup:
  stage: node-setup
  tags:
    - tfplenum-buildv2
  script: |
    echo "IP of runner is $(hostname -I | cut -d " " -f1)"
    echo "Current working directory is $(pwd)"
    echo "VM_PREFIX is $VM_PREFIX"
    START_INDEX=$(($NUM_SERVERS+$NUM_SENSORS+$NUM_SERVICE_NODES+1))
    echo "$START_INDEX"
    python3 testing/pipeline/pipeline.py \
    add-node \
    --node-type MIP \
    --deployment-type Virtual \
    --vm-prefix "$VM_PREFIX" \
    --cpu $MIP_CPU \
    --memory $MIP_MEM \
    --start-index $START_INDEX \
    --num-nodes $NUM_MIPS \
    --os-raid "$VM_RAID" \
    --dns-servers $DNS_SERVERS
  retry: 2
  artifacts:
    untracked: true
  extends: .all-mip-hw

Perform Security Scans:
  stage: security_scans
  tags:
    - tfplenum-buildv2
  script: |
    echo "IP of runner is $(hostname -I | cut -d " " -f1)"
    echo "Current working directory is $(pwd)"
    python3 testing/pipeline/pipeline.py run-oscap-scans
  only:
    variables:
      - $RUN_SECURITY_SCANS == "yes" && $PIPELINE == "developer-all"
  artifacts:
    untracked: true
  allow_failure: true

CVAH Catalog Community Apps:
  stage: robot-test-setup
  tags:
    - tfplenum-buildv2
  script: |
    echo "IP of runner is $(hostname -I | cut -d " " -f1)"
    echo "Current working directory is $(pwd)"
    python3 testing/pipeline/pipeline.py run-catalog mattermost
    python3 testing/pipeline/pipeline.py run-catalog nifi
    python3 testing/pipeline/pipeline.py run-catalog jcat-nifi
    python3 testing/pipeline/pipeline.py run-catalog redmine
    python3 testing/pipeline/pipeline.py run-catalog netflow-filebeat
  only:
    variables:
      - $RUN_INTEGRATION == "yes" && $COMMUNITY_APPS == "yes" && $PIPELINE == "developer-all"
  retry: 2

System Function Testing:
  stage: integration-test
  tags:
    - tfplenum-buildv2
  script: |
    echo "IP of runner is $(hostname -I | cut -d " " -f1)"
    echo "Current working directory is $(pwd)"
    python3 testing/pipeline/pipeline.py run-integration-tests
  needs:
    - job: robot:rulesets:sync
      optional: true
  only:
    variables:
      - $RUN_INTEGRATION == "yes" && $PIPELINE == "developer-all"
  artifacts:
    paths:
      - "./*.xml"
    reports:
      junit: "./*.xml"

Disk Stress Test:
  stage: disk-test
  tags:
    - tfplenum-buildv2
  script: |
    echo "IP of runner is $(hostname -I | cut -d " " -f1)"
    echo "Current working directory is $(pwd)"
    python3 testing/pipeline/pipeline.py run-disk-fillup-tests
  only:
    variables:
      - $RUN_INTEGRATION == "yes" && $PIPELINE == "developer-all"
  allow_failure: true

Simulate Power Failure:
  stage: test-powerfailure
  tags:
    - tfplenum-buildv2
  script: |
    echo "IP of runner is $(hostname -I | cut -d " " -f1)"
    echo "Current working directory is $(pwd)"
    python3 testing/pipeline/pipeline.py simulate-power-failure
  only:
    variables:
      - $RUN_INTEGRATION == "yes" && $PIPELINE == "developer-all"

System Function Testing2:
  stage: rerun-integration-test
  tags:
    - tfplenum-buildv2
  script: |
    echo "IP of runner is $(hostname -I | cut -d " " -f1)"
    echo "Current working directory is $(pwd)"
    python3 testing/pipeline/pipeline.py run-integration-tests
  only:
    variables:
      - $RUN_INTEGRATION == "yes" && $PIPELINE == "developer-all"
  artifacts:
    paths:
      - "./*.xml"
    reports:
      junit: "./*.xml"

DIP Cleanup:
  stage: cleanup
  tags:
    - tfplenum-buildv2
  script: |
    echo "IP of runner is $(hostname -I | cut -d " " -f1)"
    echo "Current working directory is $(pwd)"
    python3 testing/pipeline/pipeline.py run-cleanup
  only:
    variables:
      - $IS_CLEANUP == "yes" && $PIPELINE == "developer-all"
